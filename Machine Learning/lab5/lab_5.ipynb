{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "M33021_Urbanovich_Rikhard_Arnisovich_lab_5",
      "provenance": [],
      "collapsed_sections": [
        "Zpq4QOU5Wg-H",
        "i_7DyyXRWg-K",
        "_JewKs4XU-so",
        "5yiLk1P_xYQ2",
        "VlWxW3e9Wg-m",
        "D39SSh0zWg-r",
        "rhVrgkSaWg_K",
        "XsRf9T_SWg_U",
        "ylKZG2MwWg_f",
        "9hedBdcYWhAH",
        "JrqW55jgWhAR",
        "5QYTwyMtWhAZ",
        "DbJrUpARWhAd",
        "MI18l-l9WhAk",
        "1wrEGqBSWhAr",
        "gStgBJy2WhAx"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHX9p5jfTySS"
      },
      "source": [
        "## Задание 5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EnHNZtbXlH0"
      },
      "source": [
        "Набор данных тут: https://github.com/sismetanin/rureviews, также есть в папке [Data](https://drive.google.com/drive/folders/1YAMe7MiTxA-RSSd8Ex2p-L0Dspe6Gs4L). Те, кто предпочитает работать с английским языком, могут использовать набор данных `sms_spam`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMcnco3sqmu9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "from sklearn.metrics import * \n",
        "from sklearn.model_selection import train_test_split "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz0EbiSJq0sA",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d82a4279-91ec-440b-a99d-ccb3ad592e01"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b2c70362-1e0e-495a-b459-1c2365eeb73a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b2c70362-1e0e-495a-b459-1c2365eeb73a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sms_spam.csv to sms_spam.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Wz_d0VBqsRlA",
        "outputId": "77cc386a-0aa2-49c5-fdd6-5d58772d6b73"
      },
      "source": [
        "spam = pd.read_csv(io.BytesIO(uploaded['sms_spam.csv']))\n",
        "spam"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Hope you are having a good week. Just checking in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>K..give back my thanks.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Am also doing in cbe only. But have to pay.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spam</td>\n",
              "      <td>complimentary 4 STAR Ibiza Holiday or £10,000 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spam</td>\n",
              "      <td>okmail: Dear Dave this is your final notice to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5554</th>\n",
              "      <td>ham</td>\n",
              "      <td>You are a great role model. You are giving so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5555</th>\n",
              "      <td>ham</td>\n",
              "      <td>Awesome, I remember the last time we got someb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5556</th>\n",
              "      <td>spam</td>\n",
              "      <td>If you don't, your prize will go to another cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5557</th>\n",
              "      <td>spam</td>\n",
              "      <td>SMS. ac JSco: Energy is high, but u may not kn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5558</th>\n",
              "      <td>ham</td>\n",
              "      <td>Shall call now dear having food</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5559 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                               text\n",
              "0      ham  Hope you are having a good week. Just checking in\n",
              "1      ham                            K..give back my thanks.\n",
              "2      ham        Am also doing in cbe only. But have to pay.\n",
              "3     spam  complimentary 4 STAR Ibiza Holiday or £10,000 ...\n",
              "4     spam  okmail: Dear Dave this is your final notice to...\n",
              "...    ...                                                ...\n",
              "5554   ham  You are a great role model. You are giving so ...\n",
              "5555   ham  Awesome, I remember the last time we got someb...\n",
              "5556  spam  If you don't, your prize will go to another cu...\n",
              "5557  spam  SMS. ac JSco: Energy is high, but u may not kn...\n",
              "5558   ham                    Shall call now dear having food\n",
              "\n",
              "[5559 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJox-LoonoPx"
      },
      "source": [
        "Применим полученные навыки и решим задачу анализа тональности отзывов. \n",
        "\n",
        "Нужно повторить весь пайплайн от сырых текстов до получения обученной модели.\n",
        "\n",
        "Обязательные шаги предобработки:\n",
        "1. токенизация\n",
        "2. приведение к нижнему регистру\n",
        "3. удаление стоп-слов\n",
        "4. лемматизация\n",
        "5. векторизация (с настройкой гиперпараметров)\n",
        "6. построение модели\n",
        "7. оценка качества модели\n",
        "\n",
        "Обязательно использование векторайзеров:\n",
        "1. мешок n-грамм (диапазон для n подбирайте самостоятельно, запрещено использовать только униграммы).\n",
        "2. tf-idf ((диапазон для n подбирайте самостоятельно, также нужно подбирать параметры max_df, min_df, max_features)\n",
        "3. символьные n-граммы (диапазон для n подбирайте самостоятельно)\n",
        "\n",
        "В качестве классификатора нужно использовать наивный байесовский классификатор. \n",
        "\n",
        "Для сравнения векторайзеров между собой используйте precision, recall, f1-score и accuracy. Для этого сформируйте датафрейм, в котором в строках будут разные векторайзеры, а в столбцах разные метрики качества, а в  ячейках будут значения этих метрик для соответсвующих векторайзеров."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYSGHhBAtIEc"
      },
      "source": [
        "**Решение**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoB-keyYvb6W"
      },
      "source": [
        "1) токенизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x_Z25d8vfyG"
      },
      "source": [
        "import nltk # уже знакомая нам библиотека nltk\n",
        "from nltk.tokenize import word_tokenize # готовый токенизатор библиотеки nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQBe0skuv3ib",
        "outputId": "eb40a9e1-b5c2-4ce1-e37a-41e6ee285314"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXV5U8Howl6n",
        "outputId": "b6bf5994-2b9f-486e-9f22-c880b9db31db"
      },
      "source": [
        "word_tokenized_list = []\n",
        "for sms in spam.text:\n",
        "  words = word_tokenize(sms)\n",
        "  new_words = [word for word in words if word.isalnum()]\n",
        "  word_tokenized_list.append(new_words)\n",
        "len(word_tokenized_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5559"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGvDgHB19HEF"
      },
      "source": [
        "2) приведение к нижнему регистру"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA4fZwLk9Pam"
      },
      "source": [
        "for i in range(len(word_tokenized_list)):\n",
        "  for j in range(len(word_tokenized_list[i])):\n",
        "    word_tokenized_list[i][j] = word_tokenized_list[i][j].lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZq94Zmw-Ose"
      },
      "source": [
        "3) удаление стоп-слов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go1MBqiL-S_O",
        "outputId": "52db403b-f1ed-4916-9249-19ffed96f980"
      },
      "source": [
        "# импортируем стоп-слова из библиотеки nltk\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words(\"english\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mPd-1Al-1Mp"
      },
      "source": [
        "noise = stopwords.words(\"english\")\n",
        "\n",
        "word_list_without_noize = []\n",
        "for i in range(len(word_tokenized_list)):\n",
        "  element = []\n",
        "  for j in range(len(word_tokenized_list[i])):\n",
        "    if word_tokenized_list[i][j] not in noise:\n",
        "      element.append(word_tokenized_list[i][j])\n",
        "  word_list_without_noize.append(element)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDNzb9qK-74u"
      },
      "source": [
        "4) лемматизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Se7WvVW--VF",
        "outputId": "8e77fd2c-ec48-4026-e1bb-7f9f1b4bcbb0"
      },
      "source": [
        "# устанавливаем pymorphy2\n",
        "!pip install pymorphy2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51 kB 40.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 48.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhCjxH8v_skl"
      },
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "pymorphy2_analyzer = MorphAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpJdBT9t_xg_"
      },
      "source": [
        "word_list_with_lemmatization = []\n",
        "for sentence in word_list_without_noize:\n",
        "  current_sentence = \"\"\n",
        "  for word in sentence:\n",
        "    current_sentence = current_sentence + \" \" + pymorphy2_analyzer.parse(word)[0].normal_form\n",
        "  word_list_with_lemmatization.append(current_sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65QNTKXEGfQs"
      },
      "source": [
        "5) векторазирация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxmzP7XKGhyd"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(word_list_with_lemmatization, spam.type, train_size = 0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiBxXFOqOYqx"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB # наивный байесовский классификатор\n",
        "from sklearn.feature_extraction.text import CountVectorizer # модель \"мешка слов\", см. далее"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvd249Li3q2-"
      },
      "source": [
        "history = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ai7kJU9t6rN",
        "outputId": "b75d0d07-466e-49ff-9f04-ac37aa1fc684"
      },
      "source": [
        "median_length_word = 0\n",
        "words = 0\n",
        "for sentence in word_list_with_lemmatization:\n",
        "  for word in sentence:\n",
        "    median_length_word += len(word)\n",
        "  words += len(sentence.split())\n",
        "median_length_word /= words\n",
        "median_length_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.692830312609043"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4QAG_MeKriY"
      },
      "source": [
        "5.1) мешок n-грамм"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaeba1mHKYTV",
        "outputId": "1d8f614a-4e8b-466a-9e39-acc627d2dd11"
      },
      "source": [
        "for i in range (2, 6):\n",
        "  for j in range (i, 6):\n",
        "    vectorizer = CountVectorizer(ngram_range=(i, j))\n",
        "    vectorized_x_train = vectorizer.fit_transform(x_train)\n",
        "    clf = MultinomialNB()\n",
        "    clf.fit(vectorized_x_train, y_train)\n",
        "\n",
        "    vectorized_x_test = vectorizer.transform(x_test)\n",
        "    pred = clf.predict(vectorized_x_test)\n",
        "    print(f\"n-framm from {i} to {j}\")\n",
        "    print(classification_report(y_test, pred))\n",
        "\n",
        "    history_element = []\n",
        "    history_element.append(\"CountVectorizer\")\n",
        "    history_element.append(1.0)\n",
        "    history_element.append(1.0)\n",
        "    history_element.append(None)\n",
        "    history_element.append(f\"({i}, {j})\")\n",
        "    weighted_avg = precision_recall_fscore_support(y_test, pred, average='weighted')\n",
        "    history_element.append(weighted_avg[0])\n",
        "    history_element.append(weighted_avg[1])\n",
        "    history_element.append(weighted_avg[2])\n",
        "    history_element.append(accuracy_score(y_test, pred))\n",
        "    history.append(history_element)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n-framm from 2 to 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       0.97      0.78      0.87       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.97      0.89      0.92      1668\n",
            "weighted avg       0.97      0.97      0.96      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      1.00      0.98      1428\n",
            "        spam       0.97      0.79      0.87       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.97      0.89      0.92      1668\n",
            "weighted avg       0.97      0.97      0.96      1668\n",
            "\n",
            "n-framm from 2 to 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      1.00      0.98      1428\n",
            "        spam       0.97      0.79      0.87       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.97      0.89      0.92      1668\n",
            "weighted avg       0.97      0.97      0.96      1668\n",
            "\n",
            "n-framm from 2 to 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      1.00      0.98      1428\n",
            "        spam       0.97      0.79      0.87       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.97      0.89      0.92      1668\n",
            "weighted avg       0.97      0.97      0.96      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      1.00      0.96      1428\n",
            "        spam       1.00      0.56      0.72       240\n",
            "\n",
            "    accuracy                           0.94      1668\n",
            "   macro avg       0.97      0.78      0.84      1668\n",
            "weighted avg       0.94      0.94      0.93      1668\n",
            "\n",
            "n-framm from 3 to 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      1.00      0.96      1428\n",
            "        spam       1.00      0.56      0.72       240\n",
            "\n",
            "    accuracy                           0.94      1668\n",
            "   macro avg       0.97      0.78      0.84      1668\n",
            "weighted avg       0.94      0.94      0.93      1668\n",
            "\n",
            "n-framm from 3 to 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      1.00      0.96      1428\n",
            "        spam       1.00      0.56      0.72       240\n",
            "\n",
            "    accuracy                           0.94      1668\n",
            "   macro avg       0.97      0.78      0.84      1668\n",
            "weighted avg       0.94      0.94      0.93      1668\n",
            "\n",
            "n-framm from 4 to 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.92      1.00      0.96      1428\n",
            "        spam       1.00      0.52      0.68       240\n",
            "\n",
            "    accuracy                           0.93      1668\n",
            "   macro avg       0.96      0.76      0.82      1668\n",
            "weighted avg       0.94      0.93      0.92      1668\n",
            "\n",
            "n-framm from 4 to 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.92      1.00      0.96      1428\n",
            "        spam       1.00      0.52      0.68       240\n",
            "\n",
            "    accuracy                           0.93      1668\n",
            "   macro avg       0.96      0.76      0.82      1668\n",
            "weighted avg       0.94      0.93      0.92      1668\n",
            "\n",
            "n-framm from 5 to 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.92      1.00      0.96      1428\n",
            "        spam       1.00      0.49      0.66       240\n",
            "\n",
            "    accuracy                           0.93      1668\n",
            "   macro avg       0.96      0.75      0.81      1668\n",
            "weighted avg       0.93      0.93      0.92      1668\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "air22TUQZNP9"
      },
      "source": [
        "5.2) tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMN1Ps9Um1sz"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgnD8yujZZYz",
        "outputId": "5580fa44-4e61-49b8-9533-e01291aec0af"
      },
      "source": [
        "for i in range (1, 4):\n",
        "  for j in range (i, 4):\n",
        "    for max_features in [500, 1500, 4000]:\n",
        "      for min_df in [0.0, 0.0025]:\n",
        "        for max_df in [0.01, 1.0]:\n",
        "          if (max_df < min_df):\n",
        "            continue\n",
        "          \n",
        "          tfidf_vectorizer = TfidfVectorizer(ngram_range=(i, j), max_df=max_df, min_df=min_df, max_features=max_features)\n",
        "          tfidf_vectorized_x_train = tfidf_vectorizer.fit_transform(x_train)\n",
        "\n",
        "          clf = MultinomialNB()\n",
        "          clf.fit(tfidf_vectorized_x_train, y_train)\n",
        "\n",
        "          tfidf_vectorized_x_test = tfidf_vectorizer.transform(x_test)\n",
        "\n",
        "          # получаем предсказания и выводим информацию о качестве\n",
        "          pred = clf.predict(tfidf_vectorized_x_test)\n",
        "          print(f\"n-framm from {i} to {j}\")\n",
        "          print(f\"min_df = {min_df}; max_df = {max_df}; max_features = {max_features}\")\n",
        "          print(classification_report(y_test, pred))\n",
        "\n",
        "          history_element = []\n",
        "          history_element.append(\"TfidfVectorizer\")\n",
        "          history_element.append(min_df)\n",
        "          history_element.append(max_df)\n",
        "          history_element.append(max_features)\n",
        "          history_element.append(f\"({i}, {j})\")\n",
        "          weighted_avg = precision_recall_fscore_support(y_test, pred, average='weighted')\n",
        "          history_element.append(weighted_avg[0])\n",
        "          history_element.append(weighted_avg[1])\n",
        "          history_element.append(weighted_avg[2])\n",
        "          history_element.append(accuracy_score(y_test, pred))\n",
        "          history.append(history_element)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n-framm from 1 to 1\n",
            "min_df = 0.0; max_df = 0.01; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.99      0.97      1428\n",
            "        spam       0.94      0.68      0.78       240\n",
            "\n",
            "    accuracy                           0.95      1668\n",
            "   macro avg       0.94      0.83      0.88      1668\n",
            "weighted avg       0.95      0.95      0.94      1668\n",
            "\n",
            "n-framm from 1 to 1\n",
            "min_df = 0.0; max_df = 1.0; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       0.96      0.75      0.84       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.96      0.87      0.91      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 1\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.99      0.97      1428\n",
            "        spam       0.94      0.67      0.78       240\n",
            "\n",
            "    accuracy                           0.95      1668\n",
            "   macro avg       0.94      0.83      0.87      1668\n",
            "weighted avg       0.94      0.95      0.94      1668\n",
            "\n",
            "n-framm from 1 to 1\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       0.96      0.75      0.84       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.96      0.87      0.91      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 1\n",
            "min_df = 0.0; max_df = 0.01; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       1.00      0.76      0.86       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.98      0.88      0.92      1668\n",
            "weighted avg       0.97      0.97      0.96      1668\n",
            "\n",
            "n-framm from 1 to 1\n",
            "min_df = 0.0; max_df = 1.0; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      1.00      0.98      1428\n",
            "        spam       0.99      0.81      0.89       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.98      0.90      0.94      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-framm from 1 to 1\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.99      0.97      1428\n",
            "        spam       0.94      0.67      0.78       240\n",
            "\n",
            "    accuracy                           0.95      1668\n",
            "   macro avg       0.94      0.83      0.87      1668\n",
            "weighted avg       0.94      0.95      0.94      1668\n",
            "\n",
            "n-framm from 1 to 1\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.99      0.98      1428\n",
            "        spam       0.95      0.80      0.87       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.96      0.89      0.92      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 1\n",
            "min_df = 0.0; max_df = 0.01; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      1.00      0.97      1428\n",
            "        spam       1.00      0.69      0.81       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.98      0.84      0.89      1668\n",
            "weighted avg       0.96      0.96      0.95      1668\n",
            "\n",
            "n-framm from 1 to 1\n",
            "min_df = 0.0; max_df = 1.0; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       1.00      0.73      0.85       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.98      0.87      0.91      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 1\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.99      0.97      1428\n",
            "        spam       0.94      0.67      0.78       240\n",
            "\n",
            "    accuracy                           0.95      1668\n",
            "   macro avg       0.94      0.83      0.87      1668\n",
            "weighted avg       0.94      0.95      0.94      1668\n",
            "\n",
            "n-framm from 1 to 1\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.99      0.98      1428\n",
            "        spam       0.95      0.80      0.87       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.96      0.89      0.92      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 2\n",
            "min_df = 0.0; max_df = 0.01; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.99      0.97      1428\n",
            "        spam       0.91      0.68      0.78       240\n",
            "\n",
            "    accuracy                           0.94      1668\n",
            "   macro avg       0.93      0.83      0.87      1668\n",
            "weighted avg       0.94      0.94      0.94      1668\n",
            "\n",
            "n-framm from 1 to 2\n",
            "min_df = 0.0; max_df = 1.0; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       0.96      0.77      0.86       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.96      0.88      0.92      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 2\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.99      0.97      1428\n",
            "        spam       0.93      0.68      0.78       240\n",
            "\n",
            "    accuracy                           0.95      1668\n",
            "   macro avg       0.94      0.83      0.88      1668\n",
            "weighted avg       0.95      0.95      0.94      1668\n",
            "\n",
            "n-framm from 1 to 2\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       0.96      0.77      0.86       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.96      0.88      0.92      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 2\n",
            "min_df = 0.0; max_df = 0.01; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       0.98      0.75      0.85       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.97      0.88      0.92      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 2\n",
            "min_df = 0.0; max_df = 1.0; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      1.00      0.98      1428\n",
            "        spam       0.99      0.80      0.88       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.98      0.90      0.93      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-framm from 1 to 2\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.99      0.97      1428\n",
            "        spam       0.96      0.72      0.82       240\n",
            "\n",
            "    accuracy                           0.95      1668\n",
            "   macro avg       0.95      0.86      0.90      1668\n",
            "weighted avg       0.95      0.95      0.95      1668\n",
            "\n",
            "n-framm from 1 to 2\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.99      0.98      1428\n",
            "        spam       0.96      0.80      0.88       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.96      0.90      0.93      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-framm from 1 to 2\n",
            "min_df = 0.0; max_df = 0.01; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      1.00      0.98      1428\n",
            "        spam       1.00      0.70      0.82       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.98      0.85      0.90      1668\n",
            "weighted avg       0.96      0.96      0.95      1668\n",
            "\n",
            "n-framm from 1 to 2\n",
            "min_df = 0.0; max_df = 1.0; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       1.00      0.74      0.85       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.98      0.87      0.92      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 2\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.99      0.97      1428\n",
            "        spam       0.96      0.72      0.82       240\n",
            "\n",
            "    accuracy                           0.95      1668\n",
            "   macro avg       0.95      0.86      0.90      1668\n",
            "weighted avg       0.95      0.95      0.95      1668\n",
            "\n",
            "n-framm from 1 to 2\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.99      0.98      1428\n",
            "        spam       0.96      0.80      0.88       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.96      0.90      0.93      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-framm from 1 to 3\n",
            "min_df = 0.0; max_df = 0.01; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.99      0.97      1428\n",
            "        spam       0.91      0.66      0.77       240\n",
            "\n",
            "    accuracy                           0.94      1668\n",
            "   macro avg       0.93      0.83      0.87      1668\n",
            "weighted avg       0.94      0.94      0.94      1668\n",
            "\n",
            "n-framm from 1 to 3\n",
            "min_df = 0.0; max_df = 1.0; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      0.99      0.98      1428\n",
            "        spam       0.96      0.77      0.85       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.96      0.88      0.92      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 3\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.99      0.97      1428\n",
            "        spam       0.94      0.68      0.78       240\n",
            "\n",
            "    accuracy                           0.95      1668\n",
            "   macro avg       0.94      0.83      0.88      1668\n",
            "weighted avg       0.95      0.95      0.94      1668\n",
            "\n",
            "n-framm from 1 to 3\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       0.96      0.77      0.85       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.96      0.88      0.92      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 3\n",
            "min_df = 0.0; max_df = 0.01; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       0.98      0.75      0.85       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.97      0.88      0.92      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 3\n",
            "min_df = 0.0; max_df = 1.0; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       1.00      0.78      0.88       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.98      0.89      0.93      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-framm from 1 to 3\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.99      0.97      1428\n",
            "        spam       0.96      0.72      0.82       240\n",
            "\n",
            "    accuracy                           0.95      1668\n",
            "   macro avg       0.95      0.86      0.90      1668\n",
            "weighted avg       0.95      0.95      0.95      1668\n",
            "\n",
            "n-framm from 1 to 3\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.99      0.98      1428\n",
            "        spam       0.96      0.80      0.88       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.96      0.90      0.93      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-framm from 1 to 3\n",
            "min_df = 0.0; max_df = 0.01; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      1.00      0.97      1428\n",
            "        spam       1.00      0.66      0.80       240\n",
            "\n",
            "    accuracy                           0.95      1668\n",
            "   macro avg       0.97      0.83      0.88      1668\n",
            "weighted avg       0.95      0.95      0.95      1668\n",
            "\n",
            "n-framm from 1 to 3\n",
            "min_df = 0.0; max_df = 1.0; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1428\n",
            "        spam       1.00      0.73      0.85       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.98      0.87      0.91      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-framm from 1 to 3\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.95      0.99      0.97      1428\n",
            "        spam       0.96      0.72      0.82       240\n",
            "\n",
            "    accuracy                           0.95      1668\n",
            "   macro avg       0.95      0.86      0.90      1668\n",
            "weighted avg       0.95      0.95      0.95      1668\n",
            "\n",
            "n-framm from 1 to 3\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      0.99      0.98      1428\n",
            "        spam       0.96      0.80      0.88       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.96      0.90      0.93      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-framm from 2 to 2\n",
            "min_df = 0.0; max_df = 0.01; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.92      1.00      0.96      1428\n",
            "        spam       1.00      0.50      0.66       240\n",
            "\n",
            "    accuracy                           0.93      1668\n",
            "   macro avg       0.96      0.75      0.81      1668\n",
            "weighted avg       0.93      0.93      0.92      1668\n",
            "\n",
            "n-framm from 2 to 2\n",
            "min_df = 0.0; max_df = 1.0; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      1.00      0.96      1428\n",
            "        spam       1.00      0.52      0.68       240\n",
            "\n",
            "    accuracy                           0.93      1668\n",
            "   macro avg       0.96      0.76      0.82      1668\n",
            "weighted avg       0.94      0.93      0.92      1668\n",
            "\n",
            "n-framm from 2 to 2\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.32      0.49       240\n",
            "\n",
            "    accuracy                           0.90      1668\n",
            "   macro avg       0.95      0.66      0.72      1668\n",
            "weighted avg       0.91      0.90      0.88      1668\n",
            "\n",
            "n-framm from 2 to 2\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.37      0.54       240\n",
            "\n",
            "    accuracy                           0.91      1668\n",
            "   macro avg       0.95      0.68      0.74      1668\n",
            "weighted avg       0.92      0.91      0.89      1668\n",
            "\n",
            "n-framm from 2 to 2\n",
            "min_df = 0.0; max_df = 0.01; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      1.00      0.96      1428\n",
            "        spam       1.00      0.55      0.71       240\n",
            "\n",
            "    accuracy                           0.94      1668\n",
            "   macro avg       0.96      0.78      0.84      1668\n",
            "weighted avg       0.94      0.94      0.93      1668\n",
            "\n",
            "n-framm from 2 to 2\n",
            "min_df = 0.0; max_df = 1.0; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      1.00      0.96      1428\n",
            "        spam       1.00      0.55      0.71       240\n",
            "\n",
            "    accuracy                           0.94      1668\n",
            "   macro avg       0.96      0.78      0.84      1668\n",
            "weighted avg       0.94      0.94      0.93      1668\n",
            "\n",
            "n-framm from 2 to 2\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.32      0.49       240\n",
            "\n",
            "    accuracy                           0.90      1668\n",
            "   macro avg       0.95      0.66      0.72      1668\n",
            "weighted avg       0.91      0.90      0.88      1668\n",
            "\n",
            "n-framm from 2 to 2\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.37      0.54       240\n",
            "\n",
            "    accuracy                           0.91      1668\n",
            "   macro avg       0.95      0.68      0.74      1668\n",
            "weighted avg       0.92      0.91      0.89      1668\n",
            "\n",
            "n-framm from 2 to 2\n",
            "min_df = 0.0; max_df = 0.01; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      1.00      0.96      1428\n",
            "        spam       1.00      0.54      0.70       240\n",
            "\n",
            "    accuracy                           0.93      1668\n",
            "   macro avg       0.96      0.77      0.83      1668\n",
            "weighted avg       0.94      0.93      0.92      1668\n",
            "\n",
            "n-framm from 2 to 2\n",
            "min_df = 0.0; max_df = 1.0; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.93      1.00      0.96      1428\n",
            "        spam       1.00      0.55      0.71       240\n",
            "\n",
            "    accuracy                           0.93      1668\n",
            "   macro avg       0.96      0.77      0.83      1668\n",
            "weighted avg       0.94      0.93      0.93      1668\n",
            "\n",
            "n-framm from 2 to 2\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.32      0.49       240\n",
            "\n",
            "    accuracy                           0.90      1668\n",
            "   macro avg       0.95      0.66      0.72      1668\n",
            "weighted avg       0.91      0.90      0.88      1668\n",
            "\n",
            "n-framm from 2 to 2\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.37      0.54       240\n",
            "\n",
            "    accuracy                           0.91      1668\n",
            "   macro avg       0.95      0.68      0.74      1668\n",
            "weighted avg       0.92      0.91      0.89      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "min_df = 0.0; max_df = 0.01; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.91      1.00      0.95      1428\n",
            "        spam       1.00      0.42      0.59       240\n",
            "\n",
            "    accuracy                           0.92      1668\n",
            "   macro avg       0.96      0.71      0.77      1668\n",
            "weighted avg       0.92      0.92      0.90      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "min_df = 0.0; max_df = 1.0; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.91      1.00      0.96      1428\n",
            "        spam       1.00      0.44      0.61       240\n",
            "\n",
            "    accuracy                           0.92      1668\n",
            "   macro avg       0.96      0.72      0.78      1668\n",
            "weighted avg       0.93      0.92      0.91      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.32      0.49       240\n",
            "\n",
            "    accuracy                           0.90      1668\n",
            "   macro avg       0.95      0.66      0.72      1668\n",
            "weighted avg       0.91      0.90      0.88      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.36      0.53       240\n",
            "\n",
            "    accuracy                           0.91      1668\n",
            "   macro avg       0.95      0.68      0.74      1668\n",
            "weighted avg       0.92      0.91      0.89      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "min_df = 0.0; max_df = 0.01; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.92      1.00      0.96      1428\n",
            "        spam       1.00      0.51      0.67       240\n",
            "\n",
            "    accuracy                           0.93      1668\n",
            "   macro avg       0.96      0.75      0.82      1668\n",
            "weighted avg       0.93      0.93      0.92      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "min_df = 0.0; max_df = 1.0; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.92      1.00      0.96      1428\n",
            "        spam       1.00      0.51      0.67       240\n",
            "\n",
            "    accuracy                           0.93      1668\n",
            "   macro avg       0.96      0.75      0.82      1668\n",
            "weighted avg       0.93      0.93      0.92      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.32      0.49       240\n",
            "\n",
            "    accuracy                           0.90      1668\n",
            "   macro avg       0.95      0.66      0.72      1668\n",
            "weighted avg       0.91      0.90      0.88      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.36      0.53       240\n",
            "\n",
            "    accuracy                           0.91      1668\n",
            "   macro avg       0.95      0.68      0.74      1668\n",
            "weighted avg       0.92      0.91      0.89      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "min_df = 0.0; max_df = 0.01; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.92      1.00      0.96      1428\n",
            "        spam       1.00      0.48      0.65       240\n",
            "\n",
            "    accuracy                           0.93      1668\n",
            "   macro avg       0.96      0.74      0.81      1668\n",
            "weighted avg       0.93      0.93      0.91      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "min_df = 0.0; max_df = 1.0; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.92      1.00      0.96      1428\n",
            "        spam       1.00      0.52      0.68       240\n",
            "\n",
            "    accuracy                           0.93      1668\n",
            "   macro avg       0.96      0.76      0.82      1668\n",
            "weighted avg       0.94      0.93      0.92      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.32      0.49       240\n",
            "\n",
            "    accuracy                           0.90      1668\n",
            "   macro avg       0.95      0.66      0.72      1668\n",
            "weighted avg       0.91      0.90      0.88      1668\n",
            "\n",
            "n-framm from 2 to 3\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.36      0.53       240\n",
            "\n",
            "    accuracy                           0.91      1668\n",
            "   macro avg       0.95      0.68      0.74      1668\n",
            "weighted avg       0.92      0.91      0.89      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "min_df = 0.0; max_df = 0.01; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.86      1.00      0.93      1428\n",
            "        spam       1.00      0.07      0.12       240\n",
            "\n",
            "    accuracy                           0.87      1668\n",
            "   macro avg       0.93      0.53      0.53      1668\n",
            "weighted avg       0.88      0.87      0.81      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "min_df = 0.0; max_df = 1.0; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.86      1.00      0.93      1428\n",
            "        spam       1.00      0.07      0.12       240\n",
            "\n",
            "    accuracy                           0.87      1668\n",
            "   macro avg       0.93      0.53      0.53      1668\n",
            "weighted avg       0.88      0.87      0.81      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.86      1.00      0.93      1428\n",
            "        spam       1.00      0.04      0.08       240\n",
            "\n",
            "    accuracy                           0.86      1668\n",
            "   macro avg       0.93      0.52      0.50      1668\n",
            "weighted avg       0.88      0.86      0.80      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.86      1.00      0.93      1428\n",
            "        spam       1.00      0.04      0.08       240\n",
            "\n",
            "    accuracy                           0.86      1668\n",
            "   macro avg       0.93      0.52      0.50      1668\n",
            "weighted avg       0.88      0.86      0.80      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "min_df = 0.0; max_df = 0.01; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.88      1.00      0.94      1428\n",
            "        spam       1.00      0.18      0.30       240\n",
            "\n",
            "    accuracy                           0.88      1668\n",
            "   macro avg       0.94      0.59      0.62      1668\n",
            "weighted avg       0.90      0.88      0.84      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "min_df = 0.0; max_df = 1.0; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.88      1.00      0.94      1428\n",
            "        spam       1.00      0.18      0.30       240\n",
            "\n",
            "    accuracy                           0.88      1668\n",
            "   macro avg       0.94      0.59      0.62      1668\n",
            "weighted avg       0.90      0.88      0.84      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.86      1.00      0.93      1428\n",
            "        spam       1.00      0.04      0.08       240\n",
            "\n",
            "    accuracy                           0.86      1668\n",
            "   macro avg       0.93      0.52      0.50      1668\n",
            "weighted avg       0.88      0.86      0.80      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 1500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.86      1.00      0.93      1428\n",
            "        spam       1.00      0.04      0.08       240\n",
            "\n",
            "    accuracy                           0.86      1668\n",
            "   macro avg       0.93      0.52      0.50      1668\n",
            "weighted avg       0.88      0.86      0.80      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "min_df = 0.0; max_df = 0.01; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.31      0.48       240\n",
            "\n",
            "    accuracy                           0.90      1668\n",
            "   macro avg       0.95      0.66      0.71      1668\n",
            "weighted avg       0.91      0.90      0.88      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "min_df = 0.0; max_df = 1.0; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.90      1.00      0.95      1428\n",
            "        spam       1.00      0.31      0.48       240\n",
            "\n",
            "    accuracy                           0.90      1668\n",
            "   macro avg       0.95      0.66      0.71      1668\n",
            "weighted avg       0.91      0.90      0.88      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "min_df = 0.0025; max_df = 0.01; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.86      1.00      0.93      1428\n",
            "        spam       1.00      0.04      0.08       240\n",
            "\n",
            "    accuracy                           0.86      1668\n",
            "   macro avg       0.93      0.52      0.50      1668\n",
            "weighted avg       0.88      0.86      0.80      1668\n",
            "\n",
            "n-framm from 3 to 3\n",
            "min_df = 0.0025; max_df = 1.0; max_features = 4000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.86      1.00      0.93      1428\n",
            "        spam       1.00      0.04      0.08       240\n",
            "\n",
            "    accuracy                           0.86      1668\n",
            "   macro avg       0.93      0.52      0.50      1668\n",
            "weighted avg       0.88      0.86      0.80      1668\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-o-5zMVr2XA"
      },
      "source": [
        "5.3) символьные n-граммы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNJcuubFsFc7",
        "outputId": "7d441ab8-eb99-4517-8cf1-fb5da04b72ce"
      },
      "source": [
        "for i in range (3, 8):\n",
        "  for j in range (i, 8):\n",
        "    vectorizer = CountVectorizer(analyzer='char', ngram_range=(i, j))\n",
        "    vectorized_x_train = vectorizer.fit_transform(x_train)\n",
        "    clf = MultinomialNB()\n",
        "    clf.fit(vectorized_x_train, y_train)\n",
        "\n",
        "    vectorized_x_test = vectorizer.transform(x_test)\n",
        "    pred = clf.predict(vectorized_x_test)\n",
        "    print(f\"n-gramm from {i} to {j}\")\n",
        "    print(classification_report(y_test, pred))\n",
        "\n",
        "    history_element = []\n",
        "    history_element.append(\"CountVectorizer - analyzer=char\")\n",
        "    history_element.append(1.0)\n",
        "    history_element.append(1.0)\n",
        "    history_element.append(None)\n",
        "    history_element.append(f\"({i}, {j})\")\n",
        "    weighted_avg = precision_recall_fscore_support(y_test, pred, average='weighted')\n",
        "    history_element.append(weighted_avg[0])\n",
        "    history_element.append(weighted_avg[1])\n",
        "    history_element.append(weighted_avg[2])\n",
        "    history_element.append(accuracy_score(y_test, pred))\n",
        "    history.append(history_element)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n-gramm from 3 to 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.99      0.98      1428\n",
            "        spam       0.91      0.86      0.88       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.94      0.92      0.93      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-gramm from 3 to 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.98      0.98      1428\n",
            "        spam       0.91      0.89      0.90       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.94      0.94      0.94      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-gramm from 3 to 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.98      0.98      1428\n",
            "        spam       0.90      0.89      0.90       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.94      0.94      0.94      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-gramm from 3 to 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.99      0.98      1428\n",
            "        spam       0.91      0.90      0.90       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.95      0.94      0.94      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-gramm from 3 to 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.98      0.98      1428\n",
            "        spam       0.90      0.89      0.89       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.94      0.94      0.94      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-gramm from 4 to 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.98      0.98      1428\n",
            "        spam       0.90      0.90      0.90       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.94      0.94      0.94      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-gramm from 4 to 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.98      0.98      1428\n",
            "        spam       0.89      0.90      0.90       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.94      0.94      0.94      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-gramm from 4 to 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.98      0.98      1428\n",
            "        spam       0.87      0.91      0.89       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.92      0.94      0.93      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-gramm from 4 to 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.98      0.98      1428\n",
            "        spam       0.87      0.90      0.89       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.93      0.94      0.93      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-gramm from 5 to 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.98      0.98      1428\n",
            "        spam       0.87      0.91      0.89       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.93      0.94      0.94      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-gramm from 5 to 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.97      0.98      1428\n",
            "        spam       0.84      0.91      0.87       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.91      0.94      0.92      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-gramm from 5 to 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.97      0.98      1428\n",
            "        spam       0.84      0.92      0.88       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.91      0.94      0.93      1668\n",
            "weighted avg       0.96      0.96      0.96      1668\n",
            "\n",
            "n-gramm from 6 to 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.98      0.98      1428\n",
            "        spam       0.88      0.91      0.89       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.93      0.94      0.94      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n",
            "n-gramm from 6 to 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.97      0.98      1428\n",
            "        spam       0.85      0.92      0.88       240\n",
            "\n",
            "    accuracy                           0.96      1668\n",
            "   macro avg       0.92      0.95      0.93      1668\n",
            "weighted avg       0.97      0.96      0.97      1668\n",
            "\n",
            "n-gramm from 7 to 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.98      0.98      1428\n",
            "        spam       0.86      0.92      0.89       240\n",
            "\n",
            "    accuracy                           0.97      1668\n",
            "   macro avg       0.92      0.95      0.94      1668\n",
            "weighted avg       0.97      0.97      0.97      1668\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGHHkdue3AQc"
      },
      "source": [
        "Итог:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGgp2wBH3DhN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "9e71bd0c-3cbd-450c-fb55-2f47f141b7a6"
      },
      "source": [
        "df = pd.DataFrame(history, columns=['Vectorize', 'min_df', 'max_df', 'max_features', 'n-gramm', 'precision', 'recall', 'f1-score', 'accuracy'])\n",
        "df.sort_values(by=[\"accuracy\"], ascending=False).head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vectorize</th>\n",
              "      <th>min_df</th>\n",
              "      <th>max_df</th>\n",
              "      <th>max_features</th>\n",
              "      <th>n-gramm</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>CountVectorizer - analyzer=char</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(3, 6)</td>\n",
              "      <td>0.972251</td>\n",
              "      <td>0.972422</td>\n",
              "      <td>0.972325</td>\n",
              "      <td>0.972422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.972527</td>\n",
              "      <td>0.971823</td>\n",
              "      <td>0.970584</td>\n",
              "      <td>0.971823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>CountVectorizer - analyzer=char</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(4, 4)</td>\n",
              "      <td>0.971873</td>\n",
              "      <td>0.971823</td>\n",
              "      <td>0.971847</td>\n",
              "      <td>0.971823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>CountVectorizer - analyzer=char</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(3, 5)</td>\n",
              "      <td>0.970482</td>\n",
              "      <td>0.970624</td>\n",
              "      <td>0.970547</td>\n",
              "      <td>0.970624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>CountVectorizer - analyzer=char</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(3, 4)</td>\n",
              "      <td>0.970399</td>\n",
              "      <td>0.970624</td>\n",
              "      <td>0.970495</td>\n",
              "      <td>0.970624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>CountVectorizer - analyzer=char</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(4, 5)</td>\n",
              "      <td>0.970251</td>\n",
              "      <td>0.970024</td>\n",
              "      <td>0.970127</td>\n",
              "      <td>0.970024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>CountVectorizer - analyzer=char</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(3, 7)</td>\n",
              "      <td>0.969835</td>\n",
              "      <td>0.970024</td>\n",
              "      <td>0.969919</td>\n",
              "      <td>0.970024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.970829</td>\n",
              "      <td>0.970024</td>\n",
              "      <td>0.968606</td>\n",
              "      <td>0.970024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.969920</td>\n",
              "      <td>0.968825</td>\n",
              "      <td>0.967210</td>\n",
              "      <td>0.968825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>CountVectorizer - analyzer=char</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(6, 6)</td>\n",
              "      <td>0.968814</td>\n",
              "      <td>0.968225</td>\n",
              "      <td>0.968468</td>\n",
              "      <td>0.968225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>CountVectorizer - analyzer=char</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.967128</td>\n",
              "      <td>0.967626</td>\n",
              "      <td>0.967279</td>\n",
              "      <td>0.967626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>CountVectorizer - analyzer=char</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(7, 7)</td>\n",
              "      <td>0.968808</td>\n",
              "      <td>0.967626</td>\n",
              "      <td>0.968057</td>\n",
              "      <td>0.967626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>CountVectorizer - analyzer=char</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(5, 5)</td>\n",
              "      <td>0.968461</td>\n",
              "      <td>0.967626</td>\n",
              "      <td>0.967952</td>\n",
              "      <td>0.967626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.966845</td>\n",
              "      <td>0.967026</td>\n",
              "      <td>0.965790</td>\n",
              "      <td>0.967026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>CountVectorizer - analyzer=char</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(4, 7)</td>\n",
              "      <td>0.967632</td>\n",
              "      <td>0.967026</td>\n",
              "      <td>0.967278</td>\n",
              "      <td>0.967026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.966845</td>\n",
              "      <td>0.967026</td>\n",
              "      <td>0.965790</td>\n",
              "      <td>0.967026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.966845</td>\n",
              "      <td>0.967026</td>\n",
              "      <td>0.965790</td>\n",
              "      <td>0.967026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.966845</td>\n",
              "      <td>0.967026</td>\n",
              "      <td>0.965790</td>\n",
              "      <td>0.967026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>CountVectorizer - analyzer=char</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(4, 6)</td>\n",
              "      <td>0.967286</td>\n",
              "      <td>0.966427</td>\n",
              "      <td>0.966765</td>\n",
              "      <td>0.966427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(2, 3)</td>\n",
              "      <td>0.965931</td>\n",
              "      <td>0.965827</td>\n",
              "      <td>0.964325</td>\n",
              "      <td>0.965827</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Vectorize  min_df  ...  f1-score  accuracy\n",
              "85  CountVectorizer - analyzer=char  1.0000  ...  0.972325  0.972422\n",
              "15                  TfidfVectorizer  0.0000  ...  0.970584  0.971823\n",
              "87  CountVectorizer - analyzer=char  1.0000  ...  0.971847  0.971823\n",
              "84  CountVectorizer - analyzer=char  1.0000  ...  0.970547  0.970624\n",
              "83  CountVectorizer - analyzer=char  1.0000  ...  0.970495  0.970624\n",
              "88  CountVectorizer - analyzer=char  1.0000  ...  0.970127  0.970024\n",
              "86  CountVectorizer - analyzer=char  1.0000  ...  0.969919  0.970024\n",
              "27                  TfidfVectorizer  0.0000  ...  0.968606  0.970024\n",
              "39                  TfidfVectorizer  0.0000  ...  0.967210  0.968825\n",
              "94  CountVectorizer - analyzer=char  1.0000  ...  0.968468  0.968225\n",
              "82  CountVectorizer - analyzer=char  1.0000  ...  0.967279  0.967626\n",
              "96  CountVectorizer - analyzer=char  1.0000  ...  0.968057  0.967626\n",
              "91  CountVectorizer - analyzer=char  1.0000  ...  0.967952  0.967626\n",
              "45                  TfidfVectorizer  0.0025  ...  0.965790  0.967026\n",
              "90  CountVectorizer - analyzer=char  1.0000  ...  0.967278  0.967026\n",
              "41                  TfidfVectorizer  0.0025  ...  0.965790  0.967026\n",
              "33                  TfidfVectorizer  0.0025  ...  0.965790  0.967026\n",
              "29                  TfidfVectorizer  0.0025  ...  0.965790  0.967026\n",
              "89  CountVectorizer - analyzer=char  1.0000  ...  0.966765  0.966427\n",
              "1                   CountVectorizer  1.0000  ...  0.964325  0.965827\n",
              "\n",
              "[20 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QYTwyMtWhAZ"
      },
      "source": [
        "## Задание 5.2 Регулярные выражения\n",
        "\n",
        "Регулярные выражения - способ поиска и анализа строк. Например, можно понять, какие даты в наборе строк представлены в формате DD/MM/YYYY, а какие - в других форматах. \n",
        "\n",
        "Или бывает, например, что перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
        "\n",
        "Навык полезный, давайте в нём тоже потренируемся.\n",
        "\n",
        "Для работы с регулярными выражениями есть библиотека **re**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaUW5S4gWhAb"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6aYh7Osl8xr"
      },
      "source": [
        "В регулярных выражениях, кроме привычных символов-букв, есть специальные символы:\n",
        "* **?а** - ноль или один символ **а**\n",
        "* **+а** - один или более символов **а**\n",
        "* **\\*а** - ноль или более символов **а** (не путать с +)\n",
        "* **.** - любое количество любого символа\n",
        "\n",
        "Пример:\n",
        "Выражению \\*a?b. соответствуют последовательности a, ab, abc, aa, aac НО НЕ abb!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7zOFFA3l_KQ"
      },
      "source": [
        "Рассмотрим подробно несколько наиболее полезных функций:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbJrUpARWhAd"
      },
      "source": [
        "### findall\n",
        "возвращает список всех найденных непересекающихся совпадений.\n",
        "\n",
        "Регулярное выражение **ab+c.**: \n",
        "* **a** - просто символ **a**\n",
        "* **b+** - один или более символов **b**\n",
        "* **c** - просто символ **c**\n",
        "* **.** - любой символ\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2athHzKuWhAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a5c029-36a4-4523-b036-415ad6829116"
      },
      "source": [
        "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc') \n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abcd', 'abca']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9FpIw5RWhAf"
      },
      "source": [
        "Вопрос на внимательность: почему нет abcx?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqk2NpZ-A_lD"
      },
      "source": [
        "**Ответ** \n",
        "\n",
        "Как сказано вначале, метод возвращает список всех найденных *непересекающихся* совпадений. Так как метод нашёл 'abca', то 'abcx' он уже не может выделить - они имеют пересечение в тексте в виде подстроки 'a'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5ttzoxEWhAg"
      },
      "source": [
        "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZR2AEq3WhAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c966de-740d-4d4d-e461-6233ed3529d7"
      },
      "source": [
        "result_findall = re.findall('(?:\\s|^)\\w{2}', 'Example: a Docker image is a recipe for running a containerized process.')\n",
        "result_findall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ex', ' Do', ' im', ' is', ' re', ' fo', ' ru', ' co', ' pr']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI18l-l9WhAk"
      },
      "source": [
        "### split\n",
        "разделяет строку по заданному шаблону\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVKdRoc1WhAl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b5d289-8e8c-4621-fe3c-34aa130c727c"
      },
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie') \n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['itsy', ' bitsy', ' teenie', ' weenie']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10u5efuSWhAm"
      },
      "source": [
        "можно указать максимальное количество разбиений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U9EQZMwWhAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b03311-8d9f-43c7-ddd4-768419d0a2ef"
      },
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit=2) \n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['itsy', ' bitsy', ' teenie, weenie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EMcMyflWhAp"
      },
      "source": [
        "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVgPSjEOWhAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a78236ef-e42a-4a7d-83da-6e09fc91bf46"
      },
      "source": [
        "sentence_1 = 'Docker is a Linux container management toolkit with a “social” aspect, letting users publish container images and consume those published by others.'\n",
        "sentence_2 = ' A Docker image is a recipe for running a containerized process.'\n",
        "sentence_3 = ' In this guide, we build one for a simple Spring boot application.'\n",
        "sentence_4 = ' If you are NOT using a Linux machine, you need a virtualized server.'\n",
        "sentence_5 = ' If you install VirtualBox, other tools like the Mac’s boot2docker can seamlessly manage it for you.'\n",
        "sentence_6 = ' Visit VirtualBox’s download site and pick the version for your machine.'\n",
        "sentence_7 = ' Download and install.'\n",
        "sentence_8 = ' Do not worry about actually running it.'\n",
        "text = sentence_1 + sentence_2 + sentence_3 + sentence_4 + sentence_5 + sentence_6 + sentence_7 + sentence_8\n",
        "result = re.split('\\.', text, maxsplit=2)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Docker is a Linux container management toolkit with a “social” aspect, letting users publish container images and consume those published by others', ' A Docker image is a recipe for running a containerized process', ' In this guide, we build one for a simple Spring boot application. If you are NOT using a Linux machine, you need a virtualized server. If you install VirtualBox, other tools like the Mac’s boot2docker can seamlessly manage it for you. Visit VirtualBox’s download site and pick the version for your machine. Download and install. Do not worry about actually running it.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wrEGqBSWhAr"
      },
      "source": [
        "### sub\n",
        "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
        "\n",
        "параметры: (pattern, repl, string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az3KxKWwWhAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f260be-ce79-405c-b21a-5ca8345ff4b7"
      },
      "source": [
        "result = re.sub('a', 'b', 'abcabc')\n",
        "print (result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bbcbbc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD0n7_HPWhAt"
      },
      "source": [
        "**Задание**: напишите регулярное выражение, которое позволит заменить все цифры в строке на \"DIG\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Sdu7xlWhAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3789aefe-c8c4-4ce6-9403-0818b627a6e5"
      },
      "source": [
        "result = re.sub('[0-9]', 'DIG', 'Код для входа в приложение: 1234.')\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Код для входа в приложение: DIGDIGDIGDIG.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8__oi1PWhAv"
      },
      "source": [
        "**Задание**: напишите  регулярное выражение, которое позволит убрать url из строки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwNS9zt4WhAv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b0a485a-51d0-4e3a-90aa-72178267dab3"
      },
      "source": [
        "result = re.sub('(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w\\.-]*)*\\/?', '', 'регулярные выражения онлайн: https://regex101.com/')\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'регулярные выражения онлайн: '"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gStgBJy2WhAx"
      },
      "source": [
        "### compile\n",
        "компилирует регулярное выражение в отдельный объект"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JstTupisWhAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f60e13a6-9d93-46e5-f329-620f6072715f"
      },
      "source": [
        "# Пример: построение списка всех слов строки:\n",
        "prog = re.compile('[А-Яа-яё\\-]+')\n",
        "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXEXc3G0WhA2"
      },
      "source": [
        "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFvnIWbUWhA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54e19ed-06f5-4e0d-bd71-966055a80225"
      },
      "source": [
        "prog = re.compile('[А-Яа-яё\\-]{4,}')\n",
        "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Слова', 'больше', 'больше', 'слов', 'Что-то']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQDNZ3HQWhA3"
      },
      "source": [
        "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
        "\n",
        "```\n",
        "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBo8gdKHfm_A",
        "outputId": "ffa00cda-0764-441a-bd81-64e5227ef430"
      },
      "source": [
        "prog = re.compile('@[a-z0-9_\\.-]+\\.[a-z\\.]{2,6}')\n",
        "prog.findall(\"abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@gmail.com', '@test.in', '@analyticsvidhya.com', '@rest.biz']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}